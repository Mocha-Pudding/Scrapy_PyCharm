{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python内置函数zip()介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 a (11, 22, 33)\n",
      "2 b (444, 555)\n",
      "3 c (6666, 8888)\n"
     ]
    }
   ],
   "source": [
    "demo1 = [1,2,3,4,5,6,7,8,9]\n",
    "demo2 = ['a','b','c','d','e']\n",
    "demo3 = [(11,22,33),(444,555),(6666,8888)]\n",
    "\n",
    "result_list = zip(demo1,demo2,demo3)\n",
    "for i,j,k in result_list:\n",
    "    print(i,j,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对于不同长度的列表使用zip()函数，以最短的为例，在长列表中截取同短列表长度的数据，再做数据，zip()多个参数如上面所示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapy命令交互模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapy命令交互模式启动\n",
    "scrapy shell 网址[不需要引号]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 命令交互模式中函数介绍\n",
    "```\n",
    "request对网址发起请求的请求信息\n",
    "response网址服务器响应请求，发回的响应信息\n",
    "view(response)调用系统自带浏览器，查看response中保存着从网址中获取的网页数据\n",
    "fetch(url)在交互模式下，重新对一个url网址发送请求，自动更新到request和response中\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapy项目爬虫文件说明\n",
    "```\n",
    "init.py -> 保持默认，不需要做任何修改\n",
    "\n",
    "items.py ->自定义项目类的地方，也就是爬虫获取到数据之后，传入管道文件(pipelinies.py)的载体\n",
    "\n",
    "pipelines.py ->项目管道文件，对传入的项目类中的数据进行一个清理和入库\n",
    "\n",
    "settings.Py ->Scrapy项目的设置文件，例如下载延迟，项目管道文件中类的启动以及自定义中间件的启用和顺序\n",
    "\n",
    "spiders目录 ->里面有一个init.py文件，在该目录下定义爬虫类并继承scrapy.Spider\n",
    "\n",
    "middlewares.py ->中间件配置文件\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapy爬虫文件ganji.py介绍\n",
    "\n",
    "```\n",
    "name = \"zufang\":爬虫名字，如果项目中有多个爬虫，最后别重复\n",
    "\n",
    "start_urls = ['http://gz.ganji.com/fang1/yuexiu/'] :爬虫启动后自动爬取的链接，列表内可以放多个链接\n",
    "\n",
    "def parse(self, response):：爬虫启动时，爬取链接成功后自动回调的函数，默认parse，参数self和response也是必须的\n",
    "\n",
    "response.xpath(\"xpath字符串\").extract()：固定格式，如果xpath(\"\")里面不放任何字符串会报错，如果里面的字符串是/结尾，则代码会报错\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 源代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class GanjiSpider(scrapy.Spider):\n",
    "    name = \"zufang\"\n",
    "    start_urls = ['http://gz.ganji.com/fang1/yuexiu/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        print(response)\n",
    "        title_list = response.xpath(\".//div[@class='f-list-item ershoufang-list']/dl/dd[1]/a/text()\").extract()\n",
    "        money_list =  response.xpath(\".//div[@class='f-list-item ershoufang-list']/dl/dd[5]/div[1]/span[1]/text()\").extract()\n",
    "        result_list = zip(title_list, money_list)\n",
    "        for i, j in result_list:\n",
    "            print(i, \":\", j)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class GanjiSpider(scrapy.Spider):\n",
    "    name = \"zufang\"\n",
    "    start_urls = ['http://gz.ganji.com/fang1/yuexiu/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        print(response)\n",
    "        title_list = response.xpath(\".//div[@class='f-list-item ershoufang-list']/dl/dd[1]/a/text()\").extract()\n",
    "        money_list =  response.xpath(\".//div[@class='f-list-item ershoufang-list']/dl/dd[5]/div[1]/span[1]/text()\").extract()\n",
    "        result_list = zip(title_list, money_list)\n",
    "        for i, j in result_list:\n",
    "            print(i, \":\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
